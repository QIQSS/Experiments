# %% imports
OS = 'l' # 'l' | 'w'
LS_PATH = {'w':'C:/Codes/Lab-Scripts',
           'l':'/home/local/USHERBROOKE/mora0502/Codes/Lab-Scripts'}[OS]
%cd $LS_PATH

LOG_PATH = {'w':'//bob.physique.usherbrooke.ca/recherche/Dupont-Ferrier/Projets/IMEC_DD_reflecto/QBB16_SD11b_3/Spin/',
           'l':'/run/user/1338691803/gvfs/smb-share:server=bob.physique.usherbrooke.ca,share=recherche/Dupont-Ferrier/Projets/IMEC_DD_reflecto/QBB16_SD11b_3/Spin/'}\
            [OS]
from Utils import analyse as ua
from Utils import files as uf
from Utils import plot as up
from Utils import utils as uu

from Utils.plot import imshow, qplot
from alive_progress import alive_it as ai
from tqdm import tqdm
from icecream import ic

from pyHegel import fitting as fit
from pyHegel.commands import wait
import numpy as np
from matplotlib import pyplot as plt
import matplotlib

# %% PIPELINE
# t1: -1 awgoverrange, -2 peaks error, -3 not enough counted trace, -4 exp fit error
def pl(file, class_inverse=True):
    name = file.split('-')[-1]
    load_dict = uf.loadNpz(file)
    metadata, raw = load_dict.get('metadata'), load_dict.get('array')

    # take from metadata
    t1, p1, p2 = None, metadata.get('p1'), metadata.get('p2')
    timelist_raw = np.linspace(0, metadata.get('imshow_kwargs').get('x_axis'), len(raw[0]))
    if metadata.get('awg_overrange', False): return -1, p1, p2

    # cut
    cut_id_start = ua.findNearest(timelist_raw, 0.0018, 'id')+100 # remove beginning of the pulse
    cut_id_stop = -500
    arr = ua.sliceColumns(raw, cut_id_start, cut_id_stop)
    timelist = timelist_raw[cut_id_start:cut_id_stop]
    timelist = np.asarray(timelist)-timelist[0]

    # filter and stuff
    filt = ua.gaussianlbl(arr, 40)
    bins, hist = ua.histogram(filt, return_type='all')
    peaks, prop = ua.findPeaks(hist, show_plot=False, prominence=max(hist)*0.01)
    qplot(hist, bins)

    if len(peaks) != 2: return -2, p1, p2

    p0 = [0.4, 0.4, bins[peaks[0]], bins[peaks[1]], hist[peaks[0]], hist[peaks[1]]]
    dg_params = ua.ajustementDeCourbe(ua.f_doubleGaussian, bins, hist, p0=p0, show_plot=False)
    th = ua.findClassifyingThreshold(dg_params, 'min')
    clas = ua.classify(filt, th, inverse=class_inverse)
    clas_clean = np.apply_along_axis(ua.cleanTrace, arr=clas, axis=1, tolerance=60)
    #up.plotSideBySide(raw, arr, filt, clas, clas_clean, link_all=True)
    #up.plotDoubleGaussian(bins, *dg_params, hist, th, title=f"{file.split('-')[-1]}")

    stats_dict = ua.classTraces(clas_clean, timelist)
    counted_trace = stats_dict.get('low') + stats_dict.get('high')

    if counted_trace == stats_dict.get('high'): return -3, p1, p2
    if counted_trace == stats_dict.get('low'): return -3, p1, p2
    if counted_trace < 10: return -3, p1, p2

    points = [np.sum(np.where(np.asarray(stats_dict['high_fall_time']) < t, 0, 1))/counted_trace for t in timelist]
    #A, t1 = ua.fitExpDecayLinear(timelist, points, verbose=True, show_plot=True, text=file)
    t1, A = ua.ajustementDeCourbe(ua.f_expDecay, timelist, points, show_plot=False, p0=[0.006, 0.2], plot_title=name)

    return t1, p1, p2

# %% 20240821-23 map T1 a B=.8
days = [LOG_PATH + d for d in ['20240821', '20240822', '20240823']]
files = sorted(uf.fileIn(days, contains='mesureT1_oneshot', verbose=True))
resoneshot = [pl(f, False) for f in tqdm(files)]
#uf.saveToNpz(LOG_PATH+'20240821', 'resoneshot', resoneshot)
# %%% load
resoneshot = uf.loadNpz('/run/user/1338691803/gvfs/smb-share:server=bob.physique.usherbrooke.ca,share=recherche/Dupont-Ferrier/Projets/IMEC_DD_reflecto/QBB16_SD11b_3/Spin/20240821/20240826/20240826-183809-resoneshot.npz').get('array')
# %%% clean
resoneshot_clean = [(0, t[1], t[2]) if t[0] < 0 else t for t in resoneshot]
resoneshot_clean = [(0, t[1], t[2]) if t[0] > 1.0 else t for t in resoneshot_clean]
resoneshot_arr = np.asanyarray(resoneshot_clean)
# np.argmax(resoneshot_arr[:,0])
#%% plot
#map_ = uf.loadNpz(LOG_PATH+'20240821'+'/20240821-225919-transition_B=800mT_retour.npz')

kwargs = dict(
              x_axis=map_.rget('x_axis'),
              y_axis=map_.rget('y_axis'),
              x_label='P2 (V)',
              y_label='P1 (V)',
              cmap='viridis',
              cbar=False,
              cbar_label='lockin',
              scatter_points=resoneshot_clean,
              scatter_cmap='inferno_r',
              scatter_cbar_label='T1 (s)',
              scatter_cbar=True,
              scatter_size=20,
              scatter_alpha=0.7,
              figsize=[5,4],
              return_type='win')

imshow(map_.get('array'), **kwargs)

# %% 20240821 T1(B)
files100 = sorted(uf.fileIn(LOG_PATH+'20240821', contains='mesureT1_bz=100m'))
files500 = sorted(uf.fileIn(LOG_PATH+'20240821', contains='mesureT1_bz=500m'))
files800 = sorted(uf.fileIn(LOG_PATH+'20240821', contains='mesureT1_bz=800m'))
files1000 = sorted(uf.fileIn(LOG_PATH+'20240821', contains='mesureT1_bz=1000m'))
files1200 = sorted(uf.fileIn(LOG_PATH+'20240821', contains='mesureT1_bz=1200m'))

tr100 = uf.loadNpz(LOG_PATH+'20240821/20240821-190407-transition_B=100mT.npz')
tr500 = uf.loadNpz(LOG_PATH+'20240821/20240821-175122-transition_B=500mT.npz')
tr800 = uf.loadNpz(LOG_PATH+'20240820/20240820-105251_vm_transition.npz')
tr1000 = uf.loadNpz(LOG_PATH+'20240821/20240821-141006-transition_B=1T.npz')
tr1200 = uf.loadNpz(LOG_PATH+'20240821/20240821-150546-transition_B=1200mT.npz')

res100 = [pl(f) for f in tqdm(files100)]
res500 = [pl(f) for f in tqdm(files500)]
res800 = [pl(f) for f in tqdm(files800)]
res1000 = [pl(f) for f in tqdm(files1000)]
res1200 = [pl(f) for f in tqdm(files1200)]

res100_clean = [(0, t[1], t[2]) if t[0] < 0 else t for t in res100]
res500_clean = [(0, t[1], t[2]) if t[0] < 0 else t for t in res500]
res800_clean = [(0, t[1], t[2]) if t[0] < 0 else t for t in res800]
res1000_clean = [(0, t[1], t[2]) if t[0] < 0 else t for t in res1000]
res1200_clean = [(0, t[1], t[2]) if t[0] < 0 else t for t in res1200]
res1200_clean = [(0, t[1], t[2]) if t[0] > 0.07 else t for t in res1200_clean]

texts = ['100', '500', '800', '1000', '1200']
trs = [tr100, tr500, tr800, tr1000, tr1200]
ress = [res100_clean, res500_clean, res800_clean, res1000_clean, res1200_clean]

# %%% plot imgs
for tr, res, text in zip(trs, ress, texts):
    kwargs = dict(
                  x_axis=uu.recursiveDictGet(tr, 'x_axis'),
                  y_axis=uu.recursiveDictGet(tr, 'y_axis'),
                  x_label='P2 (V)',
                  y_label='P1 (V)',
                  cmap='viridis',
                  cbar=False,
                  scatter_points=res,
                  scatter_cmap='Purples',
                  scatter_cbar_label='T1 (s)',
                  scatter_cbar=True,
                  text=f"{text} mT", text_color='white',
                  figsize=[3,3])

    imshow(tr.get('array'), **kwargs)


# %%% plot traces
fig, ax = plt.subplots()

for res, text in zip(ress, texts):
    t1s = np.asarray(res)[:, 0]
    ax.plot(np.linspace(0, len(t1s), len(t1s)), t1s,
            label=f"{text} mT", marker='o')

ax.set_xlabel('detuning $\epsilon$')
ax.set_ylabel('T1 (s)')
ax.set_xticks([])
ax.legend()
plt.show()

# %% 20240820 T1 zone 1 et 2
days = ['20240816', '20240817', '20240818', '20240819']
files = sorted(uf.fileIn([LOG_PATH+day for day in days],
                         contains=('mesureT1_we', 'mesureT1_2_we',
                                   'mesureT1_z1', 'mesureT1_z2')))

# %%% compute
t1p1p2_list = [pl(f) for f in alive_it(files, spinner=None)]

# %%% post post process

overrange_list = [data for data in t1p1p2_list if data[0] == -2]
fiterror_list = [data for data in t1p1p2_list if data[0] == -1 or data[0] == -4]
zeros_list = [data for data in t1p1p2_list if data[0] == 0]
t1p1p2_clean = [data[:3]  for data in t1p1p2_list \
                  if data not in overrange_list and \
                     data not in zeros_list and \
                     data not in fiterror_list ]#and \
                     #data[0] < 0.028]

# %%% plot
l = t1p1p2_clean
pts, y, x = np.asarray(l)[:, 0].astype(float), np.asarray(l)[:, 1].astype(float), np.asarray(l)[:, 2].astype(float)

fig = plt.figure()
ax = fig.add_subplot(111)
sc = ax.scatter(x, y, c=pts, cmap='inferno', s=150)
ax.grid(True)
ax.set_xlabel('P2 read (V)')
ax.set_ylabel('P1 read (V)')

#for i, txt in enumerate(range(len(pts))):
#    ax.annotate(txt, (x[i], y[i]))

cbar = plt.colorbar(sc, ax=ax, label='T1 (s)')
plt.show()

# %%% superpose transition map:
tr_map = uf.loadNpz(LOG_PATH+'20240820/20240820-105251_vm_transition.npz')
tr_array = tr_map.get('array')
x_axis, y_axis = tr_map['metadata']['imshow_kwargs']['x_axis'], tr_map['metadata']['imshow_kwargs']['y_axis']

up.scatterOverImg(x, y, pts, x_axis, y_axis, tr_array)

# %% 20240819 T1 weekend
#!!! temps load/empty diffÃ©rent -> change cut_id_start
days = ['20240816', '20240817', '20240818']
files = uf.fileIn([LOG_PATH+day for day in days])
files = [fname for fname in sorted(files) if 'mesureT1_we' in fname]

# 2eme batch
files2 = uf.fileIn(LOG_PATH+'20240818')
files2 = [fname for fname in sorted(files2) if 'mesureT1_2_we' in fname]
files2 += uf.fileIn(LOG_PATH+'20240819')
files2 = sorted(files2)

sw_points = ua.genTrapezoidSweep(0.550, 0.557, 28, 1.03, 1.044, 1.04, 1.054, 15)
sw_points2 = ua.genTrapezoidSweep(0.550, 0.557, 28, 1.029, 1.031, 1.039, 1.041, 3)
# %%% postprocess
# t1: -2 awgoverrange, -1 threshold error, 0 exp fit error
def pl(file=files[i:=44]):
    load_dict = uf.loadNpz(file)
    metadata, raw = load_dict.get('metadata'), load_dict.get('array')

    # take from metadata
    p1, p2 = metadata.get('p1'), metadata.get('p2')
    timelist_raw = np.linspace(0, metadata.get('imshow_kwargs').get('x_axis'), len(raw[0]))

    if metadata.get('awg_overrange'):
        return -2, p1, p2
        print('overrange')

    # cut
    cut_id_start = ua.findNearest(timelist_raw, 0.0018, 'id') # remove beginning of the pulse
    cut_id_stop = -2000
    arr = raw[:, cut_id_start:cut_id_stop]
    timelist = timelist_raw[cut_id_start:cut_id_stop]
    timelist = np.asarray(timelist)-timelist[0]

    # filter and stuff
    filt = ua.gaussianLineByLine(arr, 30)
    x, hist = ua.histogram(filt, get_x_axis=True)
    params = ua.ajustementDeCourbe(ua.f_doubleGaussian, x, hist,
                p0 = [
                       [0.1, 0.5, x[20], x[-20], np.max(hist)/8, np.max(hist)/8],
                       [0.1, 0.5, x[10], x[-10], np.max(hist)/8, np.max(hist)/8],
                       [0.5, 0.5, np.mean(x), np.mean(x), np.max(hist)/8, np.max(hist)/8],
                     ],
                inspect=False, show_plot=False, verbose=True,)
    th = ua.findClassifyingThreshold(params)
    #up.plotDoubleGaussian(x, *params, hist, th, title=f"{i}")
    clas = ua.classify(filt, th, inverse=True)
    #up.imshowSideBySide(arr, filt, clas, x_axis=timelist)

    stats_dict = ua.classTraces(clas, timelist)
    counted_trace = stats_dict.get('low') + stats_dict.get('high')

    if counted_trace != 0:
        points = [np.sum(np.where(np.asarray(stats_dict['high_fall_time']) < t, 0, 1))/counted_trace for t in timelist]
        #qplot(timelist, stats)
        #fit_res = fit.fitplot(ua.f_exp, timelist, points, p0=[298.7e-6,295e-3,102.6e-6,0])
        #fit_res = fit.fitcurve(ua.f_exp, timelist, points, p0=[298.7e-6,295e-3,102.6e-6,0])
        exp_decay = ua.ajustementDeCourbe(ua.f_expDecay, timelist, points)
        t1 = exp_decay[0]
    else:
        print('no high..., t1=0')
        t1 = 0

    #plt.show()
    #wait(1)

    return t1, p1, p2

# %%% compute
p1_list, p2_list, t1_list = [], [], []

for i, f in tqdm(enumerate(files), total=len(files)):
    print(i)
    t1, p1, p2 = pl(f)
    p1_list.append(p1)
    p2_list.append(p2)
    t1_list.append(t1)

# %%% post post processing
t1_p1_p2_list = [(t1, p1, p2) for t1, p1, p2 in zip(t1_list, p1_list, p2_list)]
overrange_list = [(t1, p1, p2) for t1, p1, p2 in zip(t1_list, p1_list, p2_list) if t1 == -2]
zeros_list = [(t1, p1, p2)  for t1, p1, p2 in zip(t1_list, p1_list, p2_list) if t1 == 0]
t1_p1_p2_clean = [(t1, p1, p2)  for t1, p1, p2 in zip(t1_list, p1_list, p2_list) \
                  if (t1, p1, p2) not in overrange_list and \
                      (t1, p1, p2) not in zeros_list and \
                      #(t1, p1, p2) not in t1_p1_p2_zeros and \
                          t1 <0.35]

#t1_list_no_abb = [t1 if t1 < 1 and t1>0 else np.nan for t1 in t1_list ]

# %%% plot
l = t1_p1_p2_clean
to_plot = np.asarray(l)[:, 0], np.asarray(l)[:, 1], np.asarray(l)[:, 2]

fig = plt.figure()
ax = fig.add_subplot(111)
colors = np.divide(1, to_plot[0], out=np.zeros_like(to_plot[0]), where=to_plot[0]!=0)
sc = ax.scatter(to_plot[2], to_plot[1], c=to_plot[0], cmap='inferno', s=150)  # Use the modified colors array
ax.grid(True)
ax.set_xlabel('P2 read (V)')
ax.set_ylabel('P1 read (V)')

cbar = plt.colorbar(sc, ax=ax, label='1/T1 (s)', cmap='viridis')
plt.show()


# %% 20240816 T1 map 2, meme point.
files = uf.fileIn(LOG_PATH+'20240816')
files = [file for file in files if 'mesureT1_pm' in file]
points = ua.genTrapezoidSweep(0.551, 0.556, 6, 1.030, 1.044, 1.04, 1.05, 3)

# %%% postprocess
def pl(file=files[0]):
    load_dict = uf.loadNpz(file)
    metadata, raw = load_dict.get('metadata'), load_dict.get('array')
    if metadata.get('awg_overrange'): print('overrange')

    # take from metadata
    p1, p2 = metadata.get('p1'), metadata.get('p2')
    timelist_raw = np.linspace(0, metadata.get('imshow_kwargs').get('x_axis'), len(raw[0]))

    # cut
    cut_id_start = ua.findNearest(timelist_raw, 0.006, 'id') # remove beginning of the pulse
    cut_id_stop = -4
    arr = raw[:, cut_id_start:cut_id_stop]
    timelist = timelist_raw[cut_id_start:cut_id_stop]
    timelist = np.asarray(timelist)-timelist[0]

    # filter and stuff
    filt = ua.gaussianLineByLine(arr, 20)
    th = ua.findClassifyingThreshold(filt, show_plot=False)
    clas = ua.classify(filt, th, inverse=True)
    #imshow(clas, title=f"Read: p1={p1}, p2={p2}")


    stats_dict = ua.classTraces(clas, timelist)

    counted_trace = stats_dict.get('low') + stats_dict.get('high')
    if counted_trace != 0:
        points = [np.sum(np.where(np.asarray(stats_dict['high_fall_time']) < t, 0, 1))/counted_trace for t in timelist]
        #qplot(timelist, stats)
        fit_res = fit.fitplot(ua.f_exp, timelist, points, p0=[298.7e-6,295e-3,102.6e-6,0])
        #fit_res = fit.fitcurve(analyse.f_exp, timelist, stats, p0=[298.7e-6,295e-3,102.6e-6,0])
        t1 = fit_res[0][0]
    else:
        t1 = 0

    wait(1)
    return t1, p1, p2, points, timelist, fit_res

# %%% compute
p1_list, p2_list, t1_list, points_list= [], [], [], []
fit_res_list = []
timelist = None
for f in alive_it(files):
    t1, p1, p2, points, tl, fit_res = pl(f)
    p1_list.append(p1)
    p2_list.append(p2)
    t1_list.append(t1)
    points_list.append(points)
    fit_res_list.append(fit_res)
    timelist=  tl
# %%% std, error
params_list = np.asarray([fr[0] for fr in fit_res_list])
p_avg = np.average(params_list, axis=0)
p_std = np.std(params_list, axis=0)
p_err = p_std/np.sqrt(len(params_list))
# %%% plot

plt.figure(figsize=(5,4))
alphas = np.linspace(0.1, 0.9, len(points_list))
colors = matplotlib.colormaps['Blues'](np.linspace(0, 1, len(points_list)))

plt.rcParams.update({'text.usetex': True})
import matplotlib as mpl
mpl.rcParams.update(mpl.rcParamsDefault)
#a*np.exp(-(x+b)/tau)+c
lbl = r'$y=ae^{\frac{-(t+b)}{T_1}}+c$'
tau, a, b, c = p_avg
tau_err, a_err, b_err, c_err = p_err
lbl = (r'$y = a e^{\frac{-(t+b)}{T_1}} + c$' +
       f'\n$T_1= {tau:.4f} \pm {tau_err:.4f}$, '
       f'\n$a = {a:.4f} \pm {a_err:.4f}$'
       f'\n$b = {b:.4f} \pm {b_err:.4f}$'
       f'\n$c = {c:.4f} \pm {c_err:.4f}$')

plt.plot(timelist, ua.f_exp(timelist, *p_avg), color='red', label=lbl)
for points, alpha, c in zip(points_list, alphas, colors):
    plt.plot(timelist, points, alpha=alpha, linewidth=0.5, color=c)

plt.xlabel('time (s)')
plt.ylabel('$P_{high}$')
#plt.tick_params(axis='both', which='major', labelsize=12)
#plt.legend(prop={'size': 50})
plt.legend(prop = { "size": 60 }, loc ="upper right")  # Adjust the fontsize as needed

plt.grid()
plt.legend()
plt.show()

# %% 20240815 T1 map
# !!!! certains points sont au-delÃ  de la range de l'awg

files = uf.fileIn(LOG_PATH+'20240815', full_path=True)
files = [file for file in files if 'mesureT1' in file]

p1_list= np.linspace(1.035, 1.05, 10)
p2_list = np.linspace(0.550, 0.558, 10)

# %%% postprocess pipeline
def pl(file=files[1]):
    load_dict = uf.loadNpz(file)
    metadata, raw = load_dict.get('metadata'), load_dict.get('array')

    p1, p2 = metadata.get('p1'), metadata.get('p2')
    timelist = np.linspace(0, metadata.get('imshow_kwargs').get('x_axis'), len(raw[0]))

    cut_id_start = ua.findNearest(timelist, 0.006, 'id') # remove beginning of the pulse
    cut_id_stop = -200
    arr = raw[:, cut_id_start:cut_id_stop]
    timelist = timelist[cut_id_start:cut_id_stop]
    timelist = np.asarray(timelist)-timelist[0]

    filt = ua.gaussianLineByLine(arr, 20)
    th = ua.findClassifyingThreshold(filt, show_plot=False)
    clas = ua.classify(filt, th, inverse=True)
    #imshow(clas, title=f"Read: p1={p1}, p2={p2}")


    stats_dict = ua.classTraces(clas, timelist)

    counted_trace = stats_dict.get('low') + stats_dict.get('high')
    if counted_trace != 0:
        stats = [np.sum(np.where(np.asarray(stats_dict['high_fall_time']) < t, 0, 1))/counted_trace for t in timelist]
        #qplot(timelist, stats)
        fit_res = fit.fitplot(ua.f_exp, timelist, stats, p0=[298.7e-6,295e-3,102.6e-6,0])
        #fit_res = fit.fitcurve(analyse.f_exp, timelist, stats, p0=[298.7e-6,295e-3,102.6e-6,0])
        t1 = fit_res[0][0]
    else:
        t1 = 0

    wait(.5)
    return t1, p1, p2
# %%% build t1 map
t1_list = [] # list of tuple: [((p1,p2), t1), ]
for f in alive_it(files):
    t1, p1, p2 = pl(f)
    t1_list.append(((p1, p2), t1))

p1_values = [item[0][0] for item in t1_list]
p2_values = [item[0][1] for item in t1_list]
t1_values = [item[1] for item in t1_list]

# %%% plot
fig = plt.figure()
ax = fig.add_subplot(111)
sc = ax.scatter(p2_values, p1_values, c=t1_values, s=[v*100000 for v in t1_values], cmap='viridis')
ax.grid(True)
ax.set_xlabel('P1 read (V)')
ax.set_ylabel('P2 read (V)')
cbar = plt.colorbar(sc)
cbar.set_label('T1')
plt.show()

# %% 20240814 T1
# %%% load
data = uf.loadNpz('C:\Codes\Lab-Scripts/Spin/logs/20240815/20240815-171747-readout')
raw = data.get('array')
timelist = np.linspace(0, 0.051, len(raw[0]))
# %%% exclude first points
#print(data.get('metadata').get('pulseP1'))
cut_at_time = 0.006
cut_id = ua.findNearest(timelist, cut_at_time, 'id')
arr = raw[:, cut_id:]
timelist = timelist[cut_id:]
timelist = np.asarray(timelist)-timelist[0]

# %%% filter and stats
filt = ua.gaussianLineByLine(arr, 10)
th = ua.findClassifyingThreshold(filt, show_plot=False)
clas = ua.classify(filt, th, inverse=True)

d = ua.classTraces(clas, timelist)

# %%% stats again
counted_trace = d.get('low') + d.get('high')
stats = [np.sum(np.where(np.asarray(d['high_fall_time']) < t, 0, 1))/counted_trace for t in timelist]
fitres = fit.fitplot(ua.f_exp, timelist, stats, p0=[10e-3,1,0,0])

# %%% plot
plt.figure()
plt.plot(timelist, ua.f_exp(timelist, *fitres[0]), label='fit', color='red')
plt.plot(timelist, stats)

# %% 20240814 T1 varying load time (mauvaise mÃ©thode) -
# %%% load
path = LOG_PATH+'20240814'
path2 = LOG_PATH+'20240815'
files = uf.fileIn([path, path2])
extractTload = lambda metadata: float(metadata.get('pulseP1').split('duration')[3][1:].split(')')[0])
def loadOne(file):
    d = uf.load.loadNpz(file)
    return (extractTload(d.get('metadata')), d.get('array'))
loads = [loadOne(file) for file in files]#.sort(key=lambda t: t[0]) # [(t_load, data), ...]
acq_time = 0.007

# %%% compute
t_readout = 0.002

def onepoint(arr, i):
    print(i)
    """ filter, find threshold, classify, count high/low """
    arr = arr[:, :-5]
    id_readout = ua.findNearest(np.linspace(0, acq_time, loads[0][1].shape[1]), t_readout, 'id')

    arr = ua.gaussian(arr, sigma=10)

    th = ua.findClassifyingThreshold(arr, show_plot=False)
    arr_cls = ua.classify(arr, th)
    proba = ua.countHighLow(arr_cls[:, id_readout])
    return proba

result = [(t_load, onepoint(arr, i).get('low')) for i, (t_load, arr) in enumerate(loads[:414])] # [(t_load, proba)]
res = np.array(result[:408])
qplot(res[:,0], res[:,1])

# Pas la bonne mesure de T1 finalement.......
